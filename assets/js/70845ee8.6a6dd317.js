"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[2411],{8453:(n,e,r)=>{r.d(e,{R:()=>s,x:()=>a});var i=r(6540);const o={},t=i.createContext(o);function s(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(t.Provider,{value:e},n.children)}},8723:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"Application Development and Execution Guide/Framework-Driven AI Sample Execution/onnx","title":"ONNX","description":"ONNX\uff08\u5f00\u653e\u795e\u7ecf\u7f51\u7edc\u4ea4\u6362\uff09\u662f\u4e00\u79cd\u5bfc\u51fa\u6a21\u578b\u7684\u6807\u51c6\u683c\u5f0f\uff0c\u7528\u4e8e\u5c06\u6a21\u578b\uff08\u901a\u5e38\u662f\u5728\u50cf PyTorch \u8fd9\u6837\u7684\u6846\u67b6\u4e2d\u521b\u5efa\u7684\u6a21\u578b\uff09\u5bfc\u51fa\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u5728\u4efb\u4f55\u5730\u65b9\u8fd0\u884c\u3002\u5728 Dragonwing \u8bbe\u5907\u4e0a\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u5e26\u6709 AI Engine Direct \u7684 ONNX Runtime \u76f4\u63a5\u5728 NPU \u4e0a\u6267\u884c ONNX \u6a21\u578b\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002","source":"@site/docs/7.Application Development and Execution Guide/2.Framework-Driven AI Sample Execution/4.onnx.md","sourceDirName":"7.Application Development and Execution Guide/2.Framework-Driven AI Sample Execution","slug":"/Application Development and Execution Guide/Framework-Driven AI Sample Execution/onnx","permalink":"/ubuntu100-cn.github.io/docs/Application Development and Execution Guide/Framework-Driven AI Sample Execution/onnx","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/7.Application Development and Execution Guide/2.Framework-Driven AI Sample Execution/4.onnx.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"LiteRT / TFLite","permalink":"/ubuntu100-cn.github.io/docs/Application Development and Execution Guide/Framework-Driven AI Sample Execution/litert_tflite"},"next":{"title":"Llama.cpp","permalink":"/ubuntu100-cn.github.io/docs/Application Development and Execution Guide/Framework-Driven AI Sample Execution/llama_cpp"}}');var o=r(4848),t=r(8453);const s={},a="ONNX",l={},c=[{value:"\u5e26\u6709 AI Engine Direct \u7684 onnxruntime wheel",id:"\u5e26\u6709-ai-engine-direct-\u7684-onnxruntime-wheel",level:2},{value:"\u51c6\u5907 onnx \u6587\u4ef6",id:"\u51c6\u5907-onnx-\u6587\u4ef6",level:2},{value:"\u52a8\u6001\u5f62\u72b6",id:"\u52a8\u6001\u5f62\u72b6",level:3},{value:"\u91cf\u5316\u6a21\u578b",id:"\u91cf\u5316\u6a21\u578b",level:3},{value:"\u5728 NPU \u4e0a\u8fd0\u884c\u6a21\u578b\uff08Python\uff09",id:"\u5728-npu-\u4e0a\u8fd0\u884c\u6a21\u578bpython",level:2},{value:"\u793a\u4f8b\uff1aSqueezeNet-1.1 (Python)",id:"\u793a\u4f8bsqueezenet-11-python",level:2},{value:"\u63d0\u793a\u4e0e\u6280\u5de7",id:"\u63d0\u793a\u4e0e\u6280\u5de7",level:2},{value:"\u7981\u7528 CPU \u56de\u9000",id:"\u7981\u7528-cpu-\u56de\u9000",level:3},{value:"\u6784\u5efa onnxruntime \u5305\u7684\u65b0\u7248\u672c",id:"\u6784\u5efa-onnxruntime-\u5305\u7684\u65b0\u7248\u672c",level:3}];function d(n){const e={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"onnx",children:"ONNX"})}),"\n",(0,o.jsx)(e.p,{children:"ONNX\uff08\u5f00\u653e\u795e\u7ecf\u7f51\u7edc\u4ea4\u6362\uff09\u662f\u4e00\u79cd\u5bfc\u51fa\u6a21\u578b\u7684\u6807\u51c6\u683c\u5f0f\uff0c\u7528\u4e8e\u5c06\u6a21\u578b\uff08\u901a\u5e38\u662f\u5728\u50cf PyTorch \u8fd9\u6837\u7684\u6846\u67b6\u4e2d\u521b\u5efa\u7684\u6a21\u578b\uff09\u5bfc\u51fa\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u5728\u4efb\u4f55\u5730\u65b9\u8fd0\u884c\u3002\u5728 Dragonwing \u8bbe\u5907\u4e0a\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u5e26\u6709 AI Engine Direct \u7684 ONNX Runtime \u76f4\u63a5\u5728 NPU \u4e0a\u6267\u884c ONNX \u6a21\u578b\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002"}),"\n",(0,o.jsx)(e.h2,{id:"\u5e26\u6709-ai-engine-direct-\u7684-onnxruntime-wheel",children:"\u5e26\u6709 AI Engine Direct \u7684 onnxruntime wheel"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.code,{children:"onnxruntime"})," \u76ee\u524d\u6ca1\u6709\u9488\u5bf9\u5e26\u6709 AI Engine Direct \u7ed1\u5b9a\u7684 aarch64 Linux \u67b6\u6784\u53d1\u5e03\u9884\u6784\u5efa\u7684\u5b89\u88c5\u5305\uff08wheel \u6587\u4ef6\uff09\uff0c\u56e0\u6b64\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528 ",(0,o.jsx)(e.code,{children:"pip"})," \u6765\u5b89\u88c5\u3002\u4f60\u53ef\u4ee5\u5728\u6b64\u5904\u4e0b\u8f7d\u9884\u6784\u5efa\u7684 wheel \u6587\u4ef6\uff1a"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"https://cdn.edgeimpulse.com/qc-ai-docs/wheels/onnxruntime_qnn-1.23.0-cp312-cp312-linux_aarch64.whl",children:"onnxruntime_qnn-1.23.0-cp312-cp312-linux_aarch64.whl"})}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:["\uff08\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"pip3 install onnxruntime_qnn-*-linux_aarch64.whl"})," \u5b89\u88c5\uff09"]}),"\n",(0,o.jsxs)(e.p,{children:["\u8981\u4e3a\u5176\u4ed6 onnxruntime \u6216 Python \u7248\u672c\u6784\u5efa wheel\uff0c\u8bf7\u53c2\u9605",(0,o.jsx)(e.a,{href:"https://github.com/edgeimpulse/onnxruntime-qnn-linux-aarch64",children:"edgeimpulse/onnxruntime-qnn-linux-aarch64"}),"\u3002"]}),"\n",(0,o.jsx)(e.h2,{id:"\u51c6\u5907-onnx-\u6587\u4ef6",children:"\u51c6\u5907 onnx \u6587\u4ef6"}),"\n",(0,o.jsx)(e.p,{children:"NPU \u4ec5\u652f\u6301\u5177\u6709\u56fa\u5b9a\u8f93\u5165\u5f62\u72b6\u7684\u91cf\u5316 uint8/int8 \u6a21\u578b\u3002\u5982\u679c\u60a8\u7684\u6a21\u578b\u672a\u91cf\u5316\uff0c\u6216\u8005\u6709\u52a8\u6001\u8f93\u5165\u5f62\u72b6\uff0c\u6a21\u578b\u5c06\u81ea\u52a8\u5378\u8f7d\u5230 CPU\u3002\u4ee5\u4e0b\u662f\u6709\u5173\u51c6\u5907\u6a21\u578b\u7684\u4e00\u4e9b\u5efa\u8bae\u3002"}),"\n",(0,o.jsxs)(e.p,{children:["\u8bf7\u67e5\u770b ",(0,o.jsx)(e.a,{href:"https://docs.pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html",children:"available in the PyTorch documentation"})," \u83b7\u53d6\u5c06 PyTorch \u6a21\u578b\u5bfc\u51fa\u5230 ONNX \u7684\u5b8c\u6574\u6559\u7a0b\u3002"]}),"\n",(0,o.jsx)(e.h3,{id:"\u52a8\u6001\u5f62\u72b6",children:"\u52a8\u6001\u5f62\u72b6"}),"\n",(0,o.jsxs)(e.p,{children:["\u5982\u679c\u6a21\u578b\u5305\u542b\u52a8\u6001\u5f62\u72b6\uff0c\u5219\u9700\u8981\u5148\u5c06\u5176\u53d8\u4e3a\u56fa\u5b9a\u5f62\u72b6\u3002\u53ef\u901a\u8fc7 ",(0,o.jsx)(e.a,{href:"https://netron.app",children:"Netron"})," \u67e5\u770b\u7f51\u7edc\u7684\u5f62\u72b6\u3002"]}),"\n",(0,o.jsx)(e.p,{children:"\u4f8b\u5982\uff0c\u6b64\u6a21\u578b\u5177\u6709\u52a8\u6001\u5f62\u72b6\uff1a"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://3580193864-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxM5xrbdbelLSl7uN8oac%2Fuploads%2Fgit-blob-7a24b95e775b9580b371704771b840abc92fb72e%2Fonnxruntime1.png?alt=media",alt:"",title:"\u5177\u6709\u52a8\u6001\u5f62\u72b6\u7684\u6a21\u578b"})}),"\n",(0,o.jsxs)(e.p,{children:["\u53ef\u901a\u8fc7 ",(0,o.jsx)(e.code,{children:"onnxruntime.tools.make_dynamic_shape_fixed"})," \u8bbe\u7f6e\u56fa\u5b9a\u5f62\u72b6\uff1a"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"python3 -m onnxruntime.tools.make_dynamic_shape_fixed \\\r\n    model_without_shapes.onnx \\\r\n    model_with_shapes.onnx \\\r\n    --input_name pixel_values \\\r\n    --input_shape 1,3,224,224\n"})}),"\n",(0,o.jsx)(e.p,{children:"\u8fd9\u6b65\u4e4b\u540e\uff0c\u60a8\u7684\u6a21\u578b\u5177\u6709\u56fa\u5b9a\u5f62\u72b6\uff0c\u5e76\u53ef\u5728 NPU \u4e0a\u8fd0\u884c\u3002"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.img,{src:"https://3580193864-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FxM5xrbdbelLSl7uN8oac%2Fuploads%2Fgit-blob-fe2eb378e26e2e6583bc00e0583713a98ba1bd88%2Fonnxruntime2.png?alt=media",alt:"",title:"\u5177\u6709\u56fa\u5b9a\u5f62\u72b6\u7684 ONNX \u6a21\u578b"})}),"\n",(0,o.jsx)(e.h3,{id:"\u91cf\u5316\u6a21\u578b",children:"\u91cf\u5316\u6a21\u578b"}),"\n",(0,o.jsxs)(e.p,{children:["NPU\u4ec5\u652f\u6301uint8/int8\u91cf\u5316\u6a21\u578b\u3002\u4e0d\u652f\u6301\u7684\u6a21\u578b\u6216\u4e0d\u652f\u6301\u7684\u5c42\u5c06\u81ea\u52a8\u79fb\u56de CPU\u3002\u6709\u5173\u91cf\u5316\u6a21\u578b\u7684\u6307\u5357\uff0c\u8bf7\u89c1 ",(0,o.jsx)(e.a,{href:"https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html",children:"ONNX Runtime docs:"}),(0,o.jsx)(e.a,{href:"https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html",children:" "}),(0,o.jsx)(e.a,{href:"https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html",children:"Quantize ONNX Models"}),"\u3002"]}),"\n",(0,o.jsxs)(e.admonition,{type:"info",children:[(0,o.jsx)(e.mdxAdmonitionTitle,{}),(0,o.jsxs)(e.p,{children:["**\u4e0d\u60f3\u81ea\u5df1\u91cf\u5316\u6a21\u578b\uff1f**\u53ef\u4ee5\u4ece ",(0,o.jsx)(e.a,{href:"https://aihub.qualcomm.com",children:"Qualcomm AI Hub"})," \u4e0b\u8f7d\u4e00\u7cfb\u5217\u7684\u91cf\u5316\u6a21\u578b\uff0c\u6216\u4f7f\u7528 ",(0,o.jsx)(e.a,{href:"https://qc-ai-test.gitbook.io/qc-ai-test-docs/running-building-ai-models/edge-impulse",children:"Edge Impulse"})," \u6765\u91cf\u5316\u5df2\u6709\u7684\u6216\u5168\u65b0\u7684\u6a21\u578b\u3002"]})]}),"\n",(0,o.jsx)(e.h2,{id:"\u5728-npu-\u4e0a\u8fd0\u884c\u6a21\u578bpython",children:"\u5728 NPU \u4e0a\u8fd0\u884c\u6a21\u578b\uff08Python\uff09"}),"\n",(0,o.jsxs)(e.p,{children:["\u8981\u5c06\u6a21\u578b\u5378\u8f7d\u5230 NPU\uff0c\u60a8\u53ea\u9700\u52a0\u8f7d ",(0,o.jsx)(e.code,{children:"QNNExecutionProvider"})," \u5e76\u5728\u521b\u5efa ",(0,o.jsx)(e.code,{children:"InferenceSession"})," \u65f6\u4f20\u5165\u5373\u53ef\u3002\u4f8b\u5982\uff1a"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-py",children:'import onnxruntime as ort\r\n\r\nproviders = (("QNNExecutionProvider", {\r\n    "backend_type": "htp",\r\n    "profiling_level": "detailed",\r\n}))\r\n\r\nso = ort.SessionOptions()\r\n\r\nsess = ort.InferenceSession(MODEL_PATH, sess_options=so, providers=providers)\r\nactual_providers = sess.get_providers()\r\nprint(f"Using providers: {actual_providers}")   # will show QNNExecutionProvider,CPUExecutionProvider if QNN can be loaded\n'})}),"\n",(0,o.jsx)(e.p,{children:"\uff08\u786e\u4fdd\u4f7f\u7528\u5e26\u6709 AI Engine Direct \u7ed1\u5b9a\u7684 onnxruntime wheel\uff0c\u8be6\u89c1\u9875\u9762\u9876\u90e8\uff09"}),"\n",(0,o.jsx)(e.h2,{id:"\u793a\u4f8bsqueezenet-11-python",children:"\u793a\u4f8b\uff1aSqueezeNet-1.1 (Python)"}),"\n",(0,o.jsx)(e.p,{children:"\u5728\u5f00\u53d1\u677f\u4e0a\u6253\u5f00\u7ec8\u7aef\uff0c\u6216\u5efa\u7acb SSH \u4f1a\u8bdd\uff0c\u7136\u540e\u6267\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a"}),"\n",(0,o.jsx)(e.p,{children:"1\ufe0f\u20e3 \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u865a\u62df\u73af\u5883\uff08venv\uff09\uff0c\u5e76\u5b89\u88c5 onnxruntime\u548c Pillow\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"python3.12 -m venv .venv-onnxruntime-demo\r\nsource .venv-onnxruntime-demo/bin/activate\r\n\r\n# onnxruntime with AI Engine Direct bindings (only works on Python3.12)\r\nwget https://cdn.edgeimpulse.com/qc-ai-docs/wheels/onnxruntime_qnn-1.23.0-cp312-cp312-linux_aarch64.whl\r\npip3 install onnxruntime_qnn-1.23.0-cp312-cp312-linux_aarch64.whl\r\nrm onnxruntime*.whl\r\n\r\n# Other dependencies\r\npip3 install Pillow\n"})}),"\n",(0,o.jsxs)(e.p,{children:["2\ufe0f\u20e3 \u5982\u4e0b\u4e3a\u8fd0\u884c ",(0,o.jsx)(e.a,{href:"https://aihub.qualcomm.com/models/squeezenet1_1",children:"SqueezeNet-1.1"})," \u7684\u7aef\u5230\u7aef\u793a\u4f8b\u3002\u5c06\u6b64\u6587\u4ef6\u4fdd\u5b58\u4e3a ",(0,o.jsx)(e.code,{children:"inference_onnx.py"}),"\uff1a"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-py",children:'#!/usr/bin/env python3\r\nimport os, sys, time, urllib.request\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport onnxruntime as ort\r\n\r\ndef curr_ms():\r\n    return round(time.time() * 1000)\r\n\r\nuse_npu = True if len(sys.argv) >= 2 and sys.argv[1] == \'--use-npu\' else False\r\n\r\n# Path to your quantized ONNX model and test image (will be download automatically)\r\nMODEL_PATH = "model.onnx"\r\nMODEL_DATA_PATH = "model.data"\r\nIMAGE_PATH = "boa-constrictor.jpg"\r\nLABELS_PATH = "SqueezeNet-1.1_labels.txt"\r\n\r\nif not os.path.exists(MODEL_PATH):\r\n    print("Downloading model...")\r\n    model_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/models/SqueezeNet-1.1_w8a8.onnx\'\r\n    urllib.request.urlretrieve(model_url, MODEL_PATH)\r\n\r\nif not os.path.exists(MODEL_DATA_PATH):\r\n    print("Downloading model data...")\r\n    model_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/models/SqueezeNet-1.1_w8a8.data\'\r\n    urllib.request.urlretrieve(model_url, MODEL_DATA_PATH)\r\n\r\nif not os.path.exists(LABELS_PATH):\r\n    print("Downloading labels...")\r\n    labels_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/models/SqueezeNet-1.1_labels.txt\'\r\n    urllib.request.urlretrieve(labels_url, LABELS_PATH)\r\n\r\nif not os.path.exists(IMAGE_PATH):\r\n    print("Downloading image...")\r\n    image_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/examples/boa-constrictor.jpg\'\r\n    urllib.request.urlretrieve(image_url, IMAGE_PATH)\r\n\r\nwith open(LABELS_PATH, \'r\') as f:\r\n    labels = [line for line in f.read().splitlines() if line.strip()]\r\n\r\nproviders = []\r\nif use_npu:\r\n    providers.append(("QNNExecutionProvider", {\r\n        "backend_type": "htp",\r\n    }))\r\nelse:\r\n    providers.append("CPUExecutionProvider")\r\n\r\nso = ort.SessionOptions()\r\n\r\nsess = ort.InferenceSession(MODEL_PATH, sess_options=so, providers=providers)\r\nactual_providers = sess.get_providers()\r\nprint(f"Using providers: {actual_providers}") # Show which providers are actually loaded\r\n\r\ninputs  = sess.get_inputs()\r\noutputs = sess.get_outputs()\r\n\r\ndef load_image_for_onnx(path, H, W):\r\n    img = Image.open(path).convert("RGB").resize((W, H))\r\n    arr = np.array(img)\r\n    arr = arr.astype(np.float32) / 255.0\r\n\r\n    arr = np.transpose(arr, (2, 0, 1))  # HWC -> CHW\r\n    arr = np.expand_dims(arr, 0)        # -> NCHW\r\n\r\n    return arr\r\n\r\n# input data scaled 0..1\r\ninput_data_f32 = load_image_for_onnx(path=IMAGE_PATH, H=224, W=224)\r\n\r\n# quantize model (cannot read these params from the onnx model I believe)\r\nscale = 1.0 / 255.0\r\nzero_point = 0\r\ninput_data_u8 = np.round(input_data_f32.astype(np.float32) / float(scale)) + int(zero_point)\r\ninput_data_u8 = np.clip(input_data_u8, 0, 255).astype(np.uint8)\r\n\r\n# Warmup once\r\n_ = sess.run(None, {sess.get_inputs()[0].name: input_data_u8})\r\n\r\n# Run 10x so we can calculate avg. runtime per inference\r\nstart = curr_ms()\r\nfor i in range(10):\r\n    out = sess.run(None, {sess.get_inputs()[0].name: input_data_u8})\r\nend = curr_ms()\r\n\r\n# Image classification models in AI Hub miss a Softmax() layer at the end of the model, so add it manually\r\ndef softmax(x, axis=-1):\r\n    # subtract max for numerical stability\r\n    x_max = np.max(x, axis=axis, keepdims=True)\r\n    e_x = np.exp(x - x_max)\r\n    return e_x / np.sum(e_x, axis=axis, keepdims=True)\r\n\r\nscores = softmax(np.squeeze(out[0], axis=0))\r\n\r\n# Take top 5\r\ntop_k_idx = scores.argsort()[-5:][::-1]\r\n\r\nprint("\\nTop-5 predictions:")\r\nfor i in top_k_idx:\r\n    label = labels[i] if i < len(labels) else f"Class {i}"\r\n    print(f"{label}: score={scores[i]}")\r\n\r\nprint("")\r\nprint(f"Inference took (on average): {(end - start) / 10:.2f} ms per image")\n'})}),"\n",(0,o.jsxs)(e.blockquote,{children:["\n",(0,o.jsx)(e.p,{children:"\u6ce8\u610f\uff1a\u8be5\u811a\u672c\u5177\u6709\u786c\u7f16\u7801\u7684\u91cf\u5316\u53c2\u6570\u3002\u5982\u679c\u66f4\u6362\u6a21\u578b\uff0c\u53ef\u80fd\u9700\u8981\u66f4\u6539\u8fd9\u4e9b\u53c2\u6570\u30023\ufe0f\u20e3 \u5728 CPU \u4e0a\u8fd0\u884c\u6a21\u578b\uff1a"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"python3 inference_onnx.py\r\n\r\n# Top-5 predictions:\r\n# common iguana: score=0.3682704567909241\r\n# night snake: score=0.1186317503452301\r\n# water snake: score=0.1186317503452301\r\n# boa constrictor: score=0.0813227966427803\r\n# bullfrog: score=0.0813227966427803\r\n#\r\n# Inference took (on average): 6.50 ms per image\n"})}),"\n",(0,o.jsx)(e.p,{children:"4\ufe0f\u20e3 \u5728 NPU \u4e0a\u8fd0\u884c\u6a21\u578b\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"python3 inference_onnx.py --use-npu\r\n\r\n# Top-5 predictions:\r\n# common iguana: score=0.30427297949790955\r\n# water snake: score=0.11838366836309433\r\n# night snake: score=0.11838366836309433\r\n# boa constrictor: score=0.11838366836309433\r\n# rock python: score=0.08115273714065552\r\n#\r\n# Inference took (on average): 1.60 ms per image\n"})}),"\n",(0,o.jsx)(e.p,{children:"\u6b63\u5982\u6240\u89c1\uff0c\u8be5\u6a21\u578b\u5728 NPU \u4e0a\u8fd0\u884c\u901f\u5ea6\u660e\u663e\u66f4\u5feb\uff0c\u4f46\u6a21\u578b\u7684\u8f93\u51fa\u7565\u6709\u53d8\u5316\u3002"}),"\n",(0,o.jsx)(e.h2,{id:"\u63d0\u793a\u4e0e\u6280\u5de7",children:"\u63d0\u793a\u4e0e\u6280\u5de7"}),"\n",(0,o.jsx)(e.h3,{id:"\u7981\u7528-cpu-\u56de\u9000",children:"\u7981\u7528 CPU \u56de\u9000"}),"\n",(0,o.jsx)(e.p,{children:"\u4e3a\u4e86\u8fdb\u884c\u8c03\u8bd5\uff0c\u53ef\u80fd\u9700\u8981\u9009\u62e9\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u7981\u7528CPU\u56de\u9000\uff1a"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-py",children:'so = ort.SessionOptions()\r\nso.add_session_config_entry("session.disable_cpu_ep_fallback", "1")\n'})}),"\n",(0,o.jsx)(e.h3,{id:"\u6784\u5efa-onnxruntime-\u5305\u7684\u65b0\u7248\u672c",children:"\u6784\u5efa onnxruntime \u5305\u7684\u65b0\u7248\u672c"}),"\n",(0,o.jsxs)(e.p,{children:["\u8be6\u89c1 ",(0,o.jsx)(e.a,{href:"https://github.com/edgeimpulse/onnxruntime-qnn-linux-aarch64",children:"edgeimpulse/onnxruntime-qnn-linux-aarch64"}),"\u3002"]})]})}function p(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);